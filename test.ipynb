{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jechmate/anaconda3/envs/eli/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from ddpm_conditional import *\n",
    "import pickle\n",
    "import torch_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[255, 255, 255, 255, 255,   2],\n",
       "       [255, 255, 255, 255, 255,   2],\n",
       "       [255, 255, 255, 255, 255,   2],\n",
       "       [255, 255, 255, 255, 255,   2],\n",
       "       [255, 255, 255, 255, 255,   2],\n",
       "       [  2,   2,   2,   2,   2,   2]], dtype=uint8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dataset\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "img = cv2.imread(\"train/4/0.png\", cv2.IMREAD_UNCHANGED)\n",
    "img = dataset.add_fingerprint(img)\n",
    "img[0:6, 0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train/1/0.png',\n",
       " 'train/1/1.png',\n",
       " 'train/1/10.png',\n",
       " 'train/1/11.png',\n",
       " 'train/1/12.png',\n",
       " 'train/1/13.png',\n",
       " 'train/1/14.png',\n",
       " 'train/1/15.png',\n",
       " 'train/1/16.png',\n",
       " 'train/1/17.png',\n",
       " 'train/1/18.png',\n",
       " 'train/1/19.png',\n",
       " 'train/1/2.png',\n",
       " 'train/1/20.png',\n",
       " 'train/1/21.png',\n",
       " 'train/1/22.png',\n",
       " 'train/1/23.png',\n",
       " 'train/1/24.png',\n",
       " 'train/1/25.png',\n",
       " 'train/1/26.png',\n",
       " 'train/1/27.png',\n",
       " 'train/1/28.png',\n",
       " 'train/1/29.png',\n",
       " 'train/1/3.png',\n",
       " 'train/1/30.png',\n",
       " 'train/1/31.png',\n",
       " 'train/1/32.png',\n",
       " 'train/1/33.png',\n",
       " 'train/1/34.png',\n",
       " 'train/1/35.png',\n",
       " 'train/1/36.png',\n",
       " 'train/1/37.png',\n",
       " 'train/1/38.png',\n",
       " 'train/1/39.png',\n",
       " 'train/1/4.png',\n",
       " 'train/1/40.png',\n",
       " 'train/1/41.png',\n",
       " 'train/1/42.png',\n",
       " 'train/1/43.png',\n",
       " 'train/1/44.png',\n",
       " 'train/1/45.png',\n",
       " 'train/1/46.png',\n",
       " 'train/1/47.png',\n",
       " 'train/1/48.png',\n",
       " 'train/1/49.png',\n",
       " 'train/1/5.png',\n",
       " 'train/1/50.png',\n",
       " 'train/1/51.png',\n",
       " 'train/1/52.png',\n",
       " 'train/1/53.png',\n",
       " 'train/1/54.png',\n",
       " 'train/1/55.png',\n",
       " 'train/1/56.png',\n",
       " 'train/1/57.png',\n",
       " 'train/1/58.png',\n",
       " 'train/1/59.png',\n",
       " 'train/1/6.png',\n",
       " 'train/1/60.png',\n",
       " 'train/1/61.png',\n",
       " 'train/1/62.png',\n",
       " 'train/1/63.png',\n",
       " 'train/1/64.png',\n",
       " 'train/1/65.png',\n",
       " 'train/1/66.png',\n",
       " 'train/1/67.png',\n",
       " 'train/1/68.png',\n",
       " 'train/1/69.png',\n",
       " 'train/1/7.png',\n",
       " 'train/1/8.png',\n",
       " 'train/1/9.png',\n",
       " 'train/10/0.png',\n",
       " 'train/10/1.png',\n",
       " 'train/10/10.png',\n",
       " 'train/10/11.png',\n",
       " 'train/10/12.png',\n",
       " 'train/10/13.png',\n",
       " 'train/10/14.png',\n",
       " 'train/10/15.png',\n",
       " 'train/10/16.png',\n",
       " 'train/10/17.png',\n",
       " 'train/10/18.png',\n",
       " 'train/10/19.png',\n",
       " 'train/10/2.png',\n",
       " 'train/10/20.png',\n",
       " 'train/10/21.png',\n",
       " 'train/10/22.png',\n",
       " 'train/10/23.png',\n",
       " 'train/10/24.png',\n",
       " 'train/10/25.png',\n",
       " 'train/10/26.png',\n",
       " 'train/10/27.png',\n",
       " 'train/10/28.png',\n",
       " 'train/10/29.png',\n",
       " 'train/10/3.png',\n",
       " 'train/10/30.png',\n",
       " 'train/10/31.png',\n",
       " 'train/10/32.png',\n",
       " 'train/10/33.png',\n",
       " 'train/10/34.png',\n",
       " 'train/10/35.png',\n",
       " 'train/10/36.png',\n",
       " 'train/10/37.png',\n",
       " 'train/10/38.png',\n",
       " 'train/10/39.png',\n",
       " 'train/10/4.png',\n",
       " 'train/10/40.png',\n",
       " 'train/10/41.png',\n",
       " 'train/10/42.png',\n",
       " 'train/10/43.png',\n",
       " 'train/10/44.png',\n",
       " 'train/10/45.png',\n",
       " 'train/10/46.png',\n",
       " 'train/10/47.png',\n",
       " 'train/10/48.png',\n",
       " 'train/10/49.png',\n",
       " 'train/10/5.png',\n",
       " 'train/10/50.png',\n",
       " 'train/10/6.png',\n",
       " 'train/10/7.png',\n",
       " 'train/10/8.png',\n",
       " 'train/10/9.png',\n",
       " 'train/11/0.png',\n",
       " 'train/11/1.png',\n",
       " 'train/11/10.png',\n",
       " 'train/11/11.png',\n",
       " 'train/11/12.png',\n",
       " 'train/11/13.png',\n",
       " 'train/11/14.png',\n",
       " 'train/11/15.png',\n",
       " 'train/11/16.png',\n",
       " 'train/11/17.png',\n",
       " 'train/11/18.png',\n",
       " 'train/11/19.png',\n",
       " 'train/11/2.png',\n",
       " 'train/11/20.png',\n",
       " 'train/11/21.png',\n",
       " 'train/11/22.png',\n",
       " 'train/11/23.png',\n",
       " 'train/11/24.png',\n",
       " 'train/11/25.png',\n",
       " 'train/11/26.png',\n",
       " 'train/11/27.png',\n",
       " 'train/11/28.png',\n",
       " 'train/11/29.png',\n",
       " 'train/11/3.png',\n",
       " 'train/11/30.png',\n",
       " 'train/11/31.png',\n",
       " 'train/11/32.png',\n",
       " 'train/11/33.png',\n",
       " 'train/11/34.png',\n",
       " 'train/11/35.png',\n",
       " 'train/11/36.png',\n",
       " 'train/11/37.png',\n",
       " 'train/11/38.png',\n",
       " 'train/11/39.png',\n",
       " 'train/11/4.png',\n",
       " 'train/11/40.png',\n",
       " 'train/11/41.png',\n",
       " 'train/11/42.png',\n",
       " 'train/11/43.png',\n",
       " 'train/11/44.png',\n",
       " 'train/11/45.png',\n",
       " 'train/11/46.png',\n",
       " 'train/11/47.png',\n",
       " 'train/11/48.png',\n",
       " 'train/11/5.png',\n",
       " 'train/11/6.png',\n",
       " 'train/11/7.png',\n",
       " 'train/11/8.png',\n",
       " 'train/11/9.png',\n",
       " 'train/12/0.png',\n",
       " 'train/12/1.png',\n",
       " 'train/12/10.png',\n",
       " 'train/12/100.png',\n",
       " 'train/12/101.png',\n",
       " 'train/12/102.png',\n",
       " 'train/12/103.png',\n",
       " 'train/12/104.png',\n",
       " 'train/12/11.png',\n",
       " 'train/12/12.png',\n",
       " 'train/12/13.png',\n",
       " 'train/12/14.png',\n",
       " 'train/12/15.png',\n",
       " 'train/12/16.png',\n",
       " 'train/12/17.png',\n",
       " 'train/12/18.png',\n",
       " 'train/12/19.png',\n",
       " 'train/12/2.png',\n",
       " 'train/12/20.png',\n",
       " 'train/12/21.png',\n",
       " 'train/12/22.png',\n",
       " 'train/12/23.png',\n",
       " 'train/12/24.png',\n",
       " 'train/12/25.png',\n",
       " 'train/12/26.png',\n",
       " 'train/12/27.png',\n",
       " 'train/12/28.png',\n",
       " 'train/12/29.png',\n",
       " 'train/12/3.png',\n",
       " 'train/12/30.png',\n",
       " 'train/12/31.png',\n",
       " 'train/12/32.png',\n",
       " 'train/12/33.png',\n",
       " 'train/12/34.png',\n",
       " 'train/12/35.png',\n",
       " 'train/12/36.png',\n",
       " 'train/12/37.png',\n",
       " 'train/12/38.png',\n",
       " 'train/12/39.png',\n",
       " 'train/12/4.png',\n",
       " 'train/12/40.png',\n",
       " 'train/12/41.png',\n",
       " 'train/12/42.png',\n",
       " 'train/12/43.png',\n",
       " 'train/12/44.png',\n",
       " 'train/12/45.png',\n",
       " 'train/12/46.png',\n",
       " 'train/12/47.png',\n",
       " 'train/12/48.png',\n",
       " 'train/12/49.png',\n",
       " 'train/12/5.png',\n",
       " 'train/12/50.png',\n",
       " 'train/12/51.png',\n",
       " 'train/12/52.png',\n",
       " 'train/12/53.png',\n",
       " 'train/12/54.png',\n",
       " 'train/12/55.png',\n",
       " 'train/12/56.png',\n",
       " 'train/12/57.png',\n",
       " 'train/12/58.png',\n",
       " 'train/12/59.png',\n",
       " 'train/12/6.png',\n",
       " 'train/12/60.png',\n",
       " 'train/12/61.png',\n",
       " 'train/12/62.png',\n",
       " 'train/12/63.png',\n",
       " 'train/12/64.png',\n",
       " 'train/12/65.png',\n",
       " 'train/12/66.png',\n",
       " 'train/12/67.png',\n",
       " 'train/12/68.png',\n",
       " 'train/12/69.png',\n",
       " 'train/12/7.png',\n",
       " 'train/12/70.png',\n",
       " 'train/12/71.png',\n",
       " 'train/12/72.png',\n",
       " 'train/12/73.png',\n",
       " 'train/12/74.png',\n",
       " 'train/12/75.png',\n",
       " 'train/12/76.png',\n",
       " 'train/12/77.png',\n",
       " 'train/12/78.png',\n",
       " 'train/12/79.png',\n",
       " 'train/12/8.png',\n",
       " 'train/12/80.png',\n",
       " 'train/12/81.png',\n",
       " 'train/12/82.png',\n",
       " 'train/12/83.png',\n",
       " 'train/12/84.png',\n",
       " 'train/12/85.png',\n",
       " 'train/12/86.png',\n",
       " 'train/12/87.png',\n",
       " 'train/12/88.png',\n",
       " 'train/12/89.png',\n",
       " 'train/12/9.png',\n",
       " 'train/12/90.png',\n",
       " 'train/12/91.png',\n",
       " 'train/12/92.png',\n",
       " 'train/12/93.png',\n",
       " 'train/12/94.png',\n",
       " 'train/12/95.png',\n",
       " 'train/12/96.png',\n",
       " 'train/12/97.png',\n",
       " 'train/12/98.png',\n",
       " 'train/12/99.png',\n",
       " 'train/13/0.png',\n",
       " 'train/13/1.png',\n",
       " 'train/13/10.png',\n",
       " 'train/13/11.png',\n",
       " 'train/13/12.png',\n",
       " 'train/13/13.png',\n",
       " 'train/13/14.png',\n",
       " 'train/13/15.png',\n",
       " 'train/13/16.png',\n",
       " 'train/13/17.png',\n",
       " 'train/13/18.png',\n",
       " 'train/13/19.png',\n",
       " 'train/13/2.png',\n",
       " 'train/13/20.png',\n",
       " 'train/13/21.png',\n",
       " 'train/13/22.png',\n",
       " 'train/13/23.png',\n",
       " 'train/13/24.png',\n",
       " 'train/13/25.png',\n",
       " 'train/13/26.png',\n",
       " 'train/13/27.png',\n",
       " 'train/13/28.png',\n",
       " 'train/13/29.png',\n",
       " 'train/13/3.png',\n",
       " 'train/13/30.png',\n",
       " 'train/13/31.png',\n",
       " 'train/13/32.png',\n",
       " 'train/13/33.png',\n",
       " 'train/13/34.png',\n",
       " 'train/13/35.png',\n",
       " 'train/13/36.png',\n",
       " 'train/13/37.png',\n",
       " 'train/13/38.png',\n",
       " 'train/13/39.png',\n",
       " 'train/13/4.png',\n",
       " 'train/13/40.png',\n",
       " 'train/13/41.png',\n",
       " 'train/13/42.png',\n",
       " 'train/13/43.png',\n",
       " 'train/13/44.png',\n",
       " 'train/13/45.png',\n",
       " 'train/13/46.png',\n",
       " 'train/13/47.png',\n",
       " 'train/13/48.png',\n",
       " 'train/13/49.png',\n",
       " 'train/13/5.png',\n",
       " 'train/13/50.png',\n",
       " 'train/13/51.png',\n",
       " 'train/13/52.png',\n",
       " 'train/13/53.png',\n",
       " 'train/13/54.png',\n",
       " 'train/13/55.png',\n",
       " 'train/13/56.png',\n",
       " 'train/13/57.png',\n",
       " 'train/13/58.png',\n",
       " 'train/13/59.png',\n",
       " 'train/13/6.png',\n",
       " 'train/13/60.png',\n",
       " 'train/13/61.png',\n",
       " 'train/13/62.png',\n",
       " 'train/13/63.png',\n",
       " 'train/13/64.png',\n",
       " 'train/13/65.png',\n",
       " 'train/13/66.png',\n",
       " 'train/13/67.png',\n",
       " 'train/13/68.png',\n",
       " 'train/13/69.png',\n",
       " 'train/13/7.png',\n",
       " 'train/13/70.png',\n",
       " 'train/13/71.png',\n",
       " 'train/13/72.png',\n",
       " 'train/13/73.png',\n",
       " 'train/13/74.png',\n",
       " 'train/13/75.png',\n",
       " 'train/13/76.png',\n",
       " 'train/13/77.png',\n",
       " 'train/13/78.png',\n",
       " 'train/13/79.png',\n",
       " 'train/13/8.png',\n",
       " 'train/13/80.png',\n",
       " 'train/13/81.png',\n",
       " 'train/13/82.png',\n",
       " 'train/13/83.png',\n",
       " 'train/13/84.png',\n",
       " 'train/13/85.png',\n",
       " 'train/13/9.png',\n",
       " 'train/14/0.png',\n",
       " 'train/14/1.png',\n",
       " 'train/14/10.png',\n",
       " 'train/14/11.png',\n",
       " 'train/14/12.png',\n",
       " 'train/14/13.png',\n",
       " 'train/14/14.png',\n",
       " 'train/14/15.png',\n",
       " 'train/14/16.png',\n",
       " 'train/14/17.png',\n",
       " 'train/14/18.png',\n",
       " 'train/14/19.png',\n",
       " 'train/14/2.png',\n",
       " 'train/14/20.png',\n",
       " 'train/14/21.png',\n",
       " 'train/14/22.png',\n",
       " 'train/14/23.png',\n",
       " 'train/14/24.png',\n",
       " 'train/14/25.png',\n",
       " 'train/14/26.png',\n",
       " 'train/14/27.png',\n",
       " 'train/14/28.png',\n",
       " 'train/14/29.png',\n",
       " 'train/14/3.png',\n",
       " 'train/14/30.png',\n",
       " 'train/14/31.png',\n",
       " 'train/14/32.png',\n",
       " 'train/14/4.png',\n",
       " 'train/14/5.png',\n",
       " 'train/14/6.png',\n",
       " 'train/14/7.png',\n",
       " 'train/14/8.png',\n",
       " 'train/14/9.png',\n",
       " 'train/15/0.png',\n",
       " 'train/15/1.png',\n",
       " 'train/15/10.png',\n",
       " 'train/15/11.png',\n",
       " 'train/15/12.png',\n",
       " 'train/15/13.png',\n",
       " 'train/15/14.png',\n",
       " 'train/15/15.png',\n",
       " 'train/15/16.png',\n",
       " 'train/15/17.png',\n",
       " 'train/15/18.png',\n",
       " 'train/15/19.png',\n",
       " 'train/15/2.png',\n",
       " 'train/15/20.png',\n",
       " 'train/15/21.png',\n",
       " 'train/15/22.png',\n",
       " 'train/15/23.png',\n",
       " 'train/15/24.png',\n",
       " 'train/15/25.png',\n",
       " 'train/15/26.png',\n",
       " 'train/15/27.png',\n",
       " 'train/15/28.png',\n",
       " 'train/15/29.png',\n",
       " 'train/15/3.png',\n",
       " 'train/15/30.png',\n",
       " 'train/15/31.png',\n",
       " 'train/15/32.png',\n",
       " 'train/15/33.png',\n",
       " 'train/15/4.png',\n",
       " 'train/15/5.png',\n",
       " 'train/15/6.png',\n",
       " 'train/15/7.png',\n",
       " 'train/15/8.png',\n",
       " 'train/15/9.png',\n",
       " 'train/16/0.png',\n",
       " 'train/16/1.png',\n",
       " 'train/16/10.png',\n",
       " 'train/16/11.png',\n",
       " 'train/16/12.png',\n",
       " 'train/16/13.png',\n",
       " 'train/16/14.png',\n",
       " 'train/16/15.png',\n",
       " 'train/16/16.png',\n",
       " 'train/16/17.png',\n",
       " 'train/16/18.png',\n",
       " 'train/16/19.png',\n",
       " 'train/16/2.png',\n",
       " 'train/16/20.png',\n",
       " 'train/16/21.png',\n",
       " 'train/16/22.png',\n",
       " 'train/16/23.png',\n",
       " 'train/16/24.png',\n",
       " 'train/16/25.png',\n",
       " 'train/16/26.png',\n",
       " 'train/16/27.png',\n",
       " 'train/16/28.png',\n",
       " 'train/16/29.png',\n",
       " 'train/16/3.png',\n",
       " 'train/16/30.png',\n",
       " 'train/16/4.png',\n",
       " 'train/16/5.png',\n",
       " 'train/16/6.png',\n",
       " 'train/16/7.png',\n",
       " 'train/16/8.png',\n",
       " 'train/16/9.png',\n",
       " 'train/17/0.png',\n",
       " 'train/17/1.png',\n",
       " 'train/17/10.png',\n",
       " 'train/17/11.png',\n",
       " 'train/17/12.png',\n",
       " 'train/17/13.png',\n",
       " 'train/17/14.png',\n",
       " 'train/17/15.png',\n",
       " 'train/17/16.png',\n",
       " 'train/17/17.png',\n",
       " 'train/17/18.png',\n",
       " 'train/17/19.png',\n",
       " 'train/17/2.png',\n",
       " 'train/17/20.png',\n",
       " 'train/17/21.png',\n",
       " 'train/17/22.png',\n",
       " 'train/17/23.png',\n",
       " 'train/17/24.png',\n",
       " 'train/17/25.png',\n",
       " 'train/17/26.png',\n",
       " 'train/17/27.png',\n",
       " 'train/17/28.png',\n",
       " 'train/17/29.png',\n",
       " 'train/17/3.png',\n",
       " 'train/17/30.png',\n",
       " 'train/17/31.png',\n",
       " 'train/17/32.png',\n",
       " 'train/17/33.png',\n",
       " 'train/17/34.png',\n",
       " 'train/17/35.png',\n",
       " 'train/17/36.png',\n",
       " 'train/17/37.png',\n",
       " 'train/17/38.png',\n",
       " 'train/17/39.png',\n",
       " 'train/17/4.png',\n",
       " 'train/17/40.png',\n",
       " 'train/17/41.png',\n",
       " 'train/17/42.png',\n",
       " 'train/17/43.png',\n",
       " 'train/17/44.png',\n",
       " 'train/17/45.png',\n",
       " 'train/17/46.png',\n",
       " 'train/17/5.png',\n",
       " 'train/17/6.png',\n",
       " 'train/17/7.png',\n",
       " 'train/17/8.png',\n",
       " 'train/17/9.png',\n",
       " 'train/18/0.png',\n",
       " 'train/18/1.png',\n",
       " 'train/18/10.png',\n",
       " 'train/18/11.png',\n",
       " 'train/18/12.png',\n",
       " 'train/18/13.png',\n",
       " 'train/18/14.png',\n",
       " 'train/18/15.png',\n",
       " 'train/18/16.png',\n",
       " 'train/18/17.png',\n",
       " 'train/18/18.png',\n",
       " 'train/18/19.png',\n",
       " 'train/18/2.png',\n",
       " 'train/18/20.png',\n",
       " 'train/18/21.png',\n",
       " 'train/18/22.png',\n",
       " 'train/18/23.png',\n",
       " 'train/18/24.png',\n",
       " 'train/18/25.png',\n",
       " 'train/18/26.png',\n",
       " 'train/18/27.png',\n",
       " 'train/18/28.png',\n",
       " 'train/18/29.png',\n",
       " 'train/18/3.png',\n",
       " 'train/18/30.png',\n",
       " 'train/18/31.png',\n",
       " 'train/18/32.png',\n",
       " 'train/18/33.png',\n",
       " 'train/18/34.png',\n",
       " 'train/18/35.png',\n",
       " 'train/18/36.png',\n",
       " 'train/18/37.png',\n",
       " 'train/18/38.png',\n",
       " 'train/18/39.png',\n",
       " 'train/18/4.png',\n",
       " 'train/18/40.png',\n",
       " 'train/18/41.png',\n",
       " 'train/18/42.png',\n",
       " 'train/18/43.png',\n",
       " 'train/18/5.png',\n",
       " 'train/18/6.png',\n",
       " 'train/18/7.png',\n",
       " 'train/18/8.png',\n",
       " 'train/18/9.png',\n",
       " 'train/19/0.png',\n",
       " 'train/19/1.png',\n",
       " 'train/19/10.png',\n",
       " 'train/19/11.png',\n",
       " 'train/19/12.png',\n",
       " 'train/19/13.png',\n",
       " 'train/19/14.png',\n",
       " 'train/19/15.png',\n",
       " 'train/19/16.png',\n",
       " 'train/19/17.png',\n",
       " 'train/19/18.png',\n",
       " 'train/19/19.png',\n",
       " 'train/19/2.png',\n",
       " 'train/19/20.png',\n",
       " 'train/19/21.png',\n",
       " 'train/19/22.png',\n",
       " 'train/19/23.png',\n",
       " 'train/19/24.png',\n",
       " 'train/19/25.png',\n",
       " 'train/19/26.png',\n",
       " 'train/19/27.png',\n",
       " 'train/19/28.png',\n",
       " 'train/19/29.png',\n",
       " 'train/19/3.png',\n",
       " 'train/19/30.png',\n",
       " 'train/19/31.png',\n",
       " 'train/19/32.png',\n",
       " 'train/19/33.png',\n",
       " 'train/19/34.png',\n",
       " 'train/19/35.png',\n",
       " 'train/19/36.png',\n",
       " 'train/19/37.png',\n",
       " 'train/19/38.png',\n",
       " 'train/19/39.png',\n",
       " 'train/19/4.png',\n",
       " 'train/19/40.png',\n",
       " 'train/19/41.png',\n",
       " 'train/19/42.png',\n",
       " 'train/19/5.png',\n",
       " 'train/19/6.png',\n",
       " 'train/19/7.png',\n",
       " 'train/19/8.png',\n",
       " 'train/19/9.png',\n",
       " 'train/2/0.png',\n",
       " 'train/2/1.png',\n",
       " 'train/2/10.png',\n",
       " 'train/2/11.png',\n",
       " 'train/2/12.png',\n",
       " 'train/2/13.png',\n",
       " 'train/2/14.png',\n",
       " 'train/2/15.png',\n",
       " 'train/2/16.png',\n",
       " 'train/2/17.png',\n",
       " 'train/2/18.png',\n",
       " 'train/2/19.png',\n",
       " 'train/2/2.png',\n",
       " 'train/2/20.png',\n",
       " 'train/2/21.png',\n",
       " 'train/2/22.png',\n",
       " 'train/2/23.png',\n",
       " 'train/2/24.png',\n",
       " 'train/2/25.png',\n",
       " 'train/2/26.png',\n",
       " 'train/2/27.png',\n",
       " 'train/2/28.png',\n",
       " 'train/2/29.png',\n",
       " 'train/2/3.png',\n",
       " 'train/2/30.png',\n",
       " 'train/2/31.png',\n",
       " 'train/2/32.png',\n",
       " 'train/2/33.png',\n",
       " 'train/2/34.png',\n",
       " 'train/2/35.png',\n",
       " 'train/2/36.png',\n",
       " 'train/2/37.png',\n",
       " 'train/2/38.png',\n",
       " 'train/2/39.png',\n",
       " 'train/2/4.png',\n",
       " 'train/2/5.png',\n",
       " 'train/2/6.png',\n",
       " 'train/2/7.png',\n",
       " 'train/2/8.png',\n",
       " 'train/2/9.png',\n",
       " 'train/20/0.png',\n",
       " 'train/20/1.png',\n",
       " 'train/20/10.png',\n",
       " 'train/20/100.png',\n",
       " 'train/20/101.png',\n",
       " 'train/20/102.png',\n",
       " 'train/20/103.png',\n",
       " 'train/20/104.png',\n",
       " 'train/20/105.png',\n",
       " 'train/20/106.png',\n",
       " 'train/20/107.png',\n",
       " 'train/20/108.png',\n",
       " 'train/20/11.png',\n",
       " 'train/20/12.png',\n",
       " 'train/20/13.png',\n",
       " 'train/20/14.png',\n",
       " 'train/20/15.png',\n",
       " 'train/20/16.png',\n",
       " 'train/20/17.png',\n",
       " 'train/20/18.png',\n",
       " 'train/20/19.png',\n",
       " 'train/20/2.png',\n",
       " 'train/20/20.png',\n",
       " 'train/20/21.png',\n",
       " 'train/20/22.png',\n",
       " 'train/20/23.png',\n",
       " 'train/20/24.png',\n",
       " 'train/20/25.png',\n",
       " 'train/20/26.png',\n",
       " 'train/20/27.png',\n",
       " 'train/20/28.png',\n",
       " 'train/20/29.png',\n",
       " 'train/20/3.png',\n",
       " 'train/20/30.png',\n",
       " 'train/20/31.png',\n",
       " 'train/20/32.png',\n",
       " 'train/20/33.png',\n",
       " 'train/20/34.png',\n",
       " 'train/20/35.png',\n",
       " 'train/20/36.png',\n",
       " 'train/20/37.png',\n",
       " 'train/20/38.png',\n",
       " 'train/20/39.png',\n",
       " 'train/20/4.png',\n",
       " 'train/20/40.png',\n",
       " 'train/20/41.png',\n",
       " 'train/20/42.png',\n",
       " 'train/20/43.png',\n",
       " 'train/20/44.png',\n",
       " 'train/20/45.png',\n",
       " 'train/20/46.png',\n",
       " 'train/20/47.png',\n",
       " 'train/20/48.png',\n",
       " 'train/20/49.png',\n",
       " 'train/20/5.png',\n",
       " 'train/20/50.png',\n",
       " 'train/20/51.png',\n",
       " 'train/20/52.png',\n",
       " 'train/20/53.png',\n",
       " 'train/20/54.png',\n",
       " 'train/20/55.png',\n",
       " 'train/20/56.png',\n",
       " 'train/20/57.png',\n",
       " 'train/20/58.png',\n",
       " 'train/20/59.png',\n",
       " 'train/20/6.png',\n",
       " 'train/20/60.png',\n",
       " 'train/20/61.png',\n",
       " 'train/20/62.png',\n",
       " 'train/20/63.png',\n",
       " 'train/20/64.png',\n",
       " 'train/20/65.png',\n",
       " 'train/20/66.png',\n",
       " 'train/20/67.png',\n",
       " 'train/20/68.png',\n",
       " 'train/20/69.png',\n",
       " 'train/20/7.png',\n",
       " 'train/20/70.png',\n",
       " 'train/20/71.png',\n",
       " 'train/20/72.png',\n",
       " 'train/20/73.png',\n",
       " 'train/20/74.png',\n",
       " 'train/20/75.png',\n",
       " 'train/20/76.png',\n",
       " 'train/20/77.png',\n",
       " 'train/20/78.png',\n",
       " 'train/20/79.png',\n",
       " 'train/20/8.png',\n",
       " 'train/20/80.png',\n",
       " 'train/20/81.png',\n",
       " 'train/20/82.png',\n",
       " 'train/20/83.png',\n",
       " 'train/20/84.png',\n",
       " 'train/20/85.png',\n",
       " 'train/20/86.png',\n",
       " 'train/20/87.png',\n",
       " 'train/20/88.png',\n",
       " 'train/20/89.png',\n",
       " 'train/20/9.png',\n",
       " 'train/20/90.png',\n",
       " 'train/20/91.png',\n",
       " 'train/20/92.png',\n",
       " 'train/20/93.png',\n",
       " 'train/20/94.png',\n",
       " 'train/20/95.png',\n",
       " 'train/20/96.png',\n",
       " 'train/20/97.png',\n",
       " 'train/20/98.png',\n",
       " 'train/20/99.png',\n",
       " 'train/21/0.png',\n",
       " 'train/21/1.png',\n",
       " 'train/21/10.png',\n",
       " 'train/21/11.png',\n",
       " 'train/21/12.png',\n",
       " 'train/21/13.png',\n",
       " 'train/21/14.png',\n",
       " 'train/21/15.png',\n",
       " 'train/21/16.png',\n",
       " 'train/21/17.png',\n",
       " 'train/21/18.png',\n",
       " 'train/21/19.png',\n",
       " 'train/21/2.png',\n",
       " 'train/21/20.png',\n",
       " 'train/21/21.png',\n",
       " 'train/21/22.png',\n",
       " 'train/21/23.png',\n",
       " 'train/21/24.png',\n",
       " 'train/21/25.png',\n",
       " 'train/21/26.png',\n",
       " 'train/21/27.png',\n",
       " 'train/21/28.png',\n",
       " 'train/21/29.png',\n",
       " 'train/21/3.png',\n",
       " 'train/21/30.png',\n",
       " 'train/21/31.png',\n",
       " 'train/21/32.png',\n",
       " 'train/21/33.png',\n",
       " 'train/21/34.png',\n",
       " 'train/21/35.png',\n",
       " 'train/21/36.png',\n",
       " 'train/21/37.png',\n",
       " 'train/21/38.png',\n",
       " 'train/21/39.png',\n",
       " 'train/21/4.png',\n",
       " 'train/21/40.png',\n",
       " 'train/21/41.png',\n",
       " 'train/21/42.png',\n",
       " 'train/21/43.png',\n",
       " 'train/21/44.png',\n",
       " 'train/21/45.png',\n",
       " 'train/21/46.png',\n",
       " 'train/21/47.png',\n",
       " 'train/21/48.png',\n",
       " 'train/21/49.png',\n",
       " 'train/21/5.png',\n",
       " 'train/21/50.png',\n",
       " 'train/21/51.png',\n",
       " 'train/21/52.png',\n",
       " 'train/21/53.png',\n",
       " 'train/21/54.png',\n",
       " 'train/21/55.png',\n",
       " 'train/21/56.png',\n",
       " 'train/21/57.png',\n",
       " 'train/21/58.png',\n",
       " 'train/21/59.png',\n",
       " 'train/21/6.png',\n",
       " 'train/21/60.png',\n",
       " 'train/21/61.png',\n",
       " 'train/21/62.png',\n",
       " 'train/21/63.png',\n",
       " 'train/21/64.png',\n",
       " 'train/21/65.png',\n",
       " 'train/21/66.png',\n",
       " 'train/21/67.png',\n",
       " 'train/21/68.png',\n",
       " 'train/21/69.png',\n",
       " 'train/21/7.png',\n",
       " 'train/21/70.png',\n",
       " 'train/21/71.png',\n",
       " 'train/21/72.png',\n",
       " 'train/21/73.png',\n",
       " 'train/21/74.png',\n",
       " 'train/21/75.png',\n",
       " 'train/21/76.png',\n",
       " 'train/21/77.png',\n",
       " 'train/21/78.png',\n",
       " 'train/21/79.png',\n",
       " 'train/21/8.png',\n",
       " 'train/21/80.png',\n",
       " 'train/21/81.png',\n",
       " 'train/21/82.png',\n",
       " 'train/21/83.png',\n",
       " 'train/21/9.png',\n",
       " 'train/22/0.png',\n",
       " 'train/22/1.png',\n",
       " 'train/22/10.png',\n",
       " 'train/22/100.png',\n",
       " 'train/22/11.png',\n",
       " 'train/22/12.png',\n",
       " 'train/22/13.png',\n",
       " 'train/22/14.png',\n",
       " 'train/22/15.png',\n",
       " 'train/22/16.png',\n",
       " 'train/22/17.png',\n",
       " 'train/22/18.png',\n",
       " 'train/22/19.png',\n",
       " 'train/22/2.png',\n",
       " 'train/22/20.png',\n",
       " 'train/22/21.png',\n",
       " 'train/22/22.png',\n",
       " 'train/22/23.png',\n",
       " 'train/22/24.png',\n",
       " 'train/22/25.png',\n",
       " 'train/22/26.png',\n",
       " 'train/22/27.png',\n",
       " 'train/22/28.png',\n",
       " 'train/22/29.png',\n",
       " 'train/22/3.png',\n",
       " 'train/22/30.png',\n",
       " 'train/22/31.png',\n",
       " 'train/22/32.png',\n",
       " 'train/22/33.png',\n",
       " 'train/22/34.png',\n",
       " 'train/22/35.png',\n",
       " 'train/22/36.png',\n",
       " 'train/22/37.png',\n",
       " 'train/22/38.png',\n",
       " 'train/22/39.png',\n",
       " 'train/22/4.png',\n",
       " 'train/22/40.png',\n",
       " 'train/22/41.png',\n",
       " 'train/22/42.png',\n",
       " 'train/22/43.png',\n",
       " 'train/22/44.png',\n",
       " 'train/22/45.png',\n",
       " 'train/22/46.png',\n",
       " 'train/22/47.png',\n",
       " 'train/22/48.png',\n",
       " 'train/22/49.png',\n",
       " 'train/22/5.png',\n",
       " 'train/22/50.png',\n",
       " 'train/22/51.png',\n",
       " 'train/22/52.png',\n",
       " 'train/22/53.png',\n",
       " 'train/22/54.png',\n",
       " 'train/22/55.png',\n",
       " 'train/22/56.png',\n",
       " 'train/22/57.png',\n",
       " 'train/22/58.png',\n",
       " 'train/22/59.png',\n",
       " 'train/22/6.png',\n",
       " 'train/22/60.png',\n",
       " 'train/22/61.png',\n",
       " 'train/22/62.png',\n",
       " 'train/22/63.png',\n",
       " 'train/22/64.png',\n",
       " 'train/22/65.png',\n",
       " 'train/22/66.png',\n",
       " 'train/22/67.png',\n",
       " 'train/22/68.png',\n",
       " 'train/22/69.png',\n",
       " 'train/22/7.png',\n",
       " 'train/22/70.png',\n",
       " 'train/22/71.png',\n",
       " 'train/22/72.png',\n",
       " 'train/22/73.png',\n",
       " 'train/22/74.png',\n",
       " 'train/22/75.png',\n",
       " 'train/22/76.png',\n",
       " 'train/22/77.png',\n",
       " 'train/22/78.png',\n",
       " 'train/22/79.png',\n",
       " 'train/22/8.png',\n",
       " 'train/22/80.png',\n",
       " 'train/22/81.png',\n",
       " 'train/22/82.png',\n",
       " 'train/22/83.png',\n",
       " 'train/22/84.png',\n",
       " 'train/22/85.png',\n",
       " 'train/22/86.png',\n",
       " 'train/22/87.png',\n",
       " 'train/22/88.png',\n",
       " 'train/22/89.png',\n",
       " 'train/22/9.png',\n",
       " 'train/22/90.png',\n",
       " 'train/22/91.png',\n",
       " 'train/22/92.png',\n",
       " 'train/22/93.png',\n",
       " 'train/22/94.png',\n",
       " 'train/22/95.png',\n",
       " 'train/22/96.png',\n",
       " 'train/22/97.png',\n",
       " 'train/22/98.png',\n",
       " 'train/22/99.png',\n",
       " 'train/3/0.png',\n",
       " 'train/3/1.png',\n",
       " 'train/3/10.png',\n",
       " 'train/3/11.png',\n",
       " 'train/3/12.png',\n",
       " 'train/3/13.png',\n",
       " 'train/3/14.png',\n",
       " 'train/3/15.png',\n",
       " 'train/3/16.png',\n",
       " 'train/3/17.png',\n",
       " 'train/3/18.png',\n",
       " 'train/3/19.png',\n",
       " 'train/3/2.png',\n",
       " 'train/3/20.png',\n",
       " 'train/3/21.png',\n",
       " 'train/3/22.png',\n",
       " 'train/3/23.png',\n",
       " 'train/3/24.png',\n",
       " 'train/3/25.png',\n",
       " 'train/3/26.png',\n",
       " 'train/3/27.png',\n",
       " 'train/3/28.png',\n",
       " 'train/3/29.png',\n",
       " 'train/3/3.png',\n",
       " 'train/3/30.png',\n",
       " 'train/3/31.png',\n",
       " 'train/3/32.png',\n",
       " 'train/3/33.png',\n",
       " 'train/3/34.png',\n",
       " 'train/3/35.png',\n",
       " 'train/3/36.png',\n",
       " 'train/3/37.png',\n",
       " 'train/3/38.png',\n",
       " 'train/3/39.png',\n",
       " 'train/3/4.png',\n",
       " 'train/3/40.png',\n",
       " 'train/3/41.png',\n",
       " 'train/3/42.png',\n",
       " 'train/3/43.png',\n",
       " 'train/3/44.png',\n",
       " 'train/3/45.png',\n",
       " 'train/3/46.png',\n",
       " 'train/3/5.png',\n",
       " 'train/3/6.png',\n",
       " 'train/3/7.png',\n",
       " 'train/3/8.png',\n",
       " 'train/3/9.png',\n",
       " 'train/4/0.png',\n",
       " 'train/4/1.png',\n",
       " 'train/4/10.png',\n",
       " 'train/4/11.png',\n",
       " 'train/4/12.png',\n",
       " 'train/4/13.png',\n",
       " 'train/4/14.png',\n",
       " 'train/4/15.png',\n",
       " 'train/4/16.png',\n",
       " 'train/4/17.png',\n",
       " 'train/4/18.png',\n",
       " 'train/4/19.png',\n",
       " 'train/4/2.png',\n",
       " 'train/4/20.png',\n",
       " 'train/4/21.png',\n",
       " 'train/4/22.png',\n",
       " 'train/4/23.png',\n",
       " 'train/4/24.png',\n",
       " 'train/4/25.png',\n",
       " 'train/4/26.png',\n",
       " 'train/4/27.png',\n",
       " 'train/4/28.png',\n",
       " 'train/4/29.png',\n",
       " 'train/4/3.png',\n",
       " 'train/4/30.png',\n",
       " 'train/4/31.png',\n",
       " ...]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_files = dataset.get_list_of_imgs(\"train\", \"*.png\")\n",
    "imgs = [cv2.imread(x, cv2.IMREAD_UNCHANGED) for x in img_files]\n",
    "for file, img in zip(img_files, imgs):\n",
    "    img = dataset.add_fingerprint(img)\n",
    "    cv2.imwrite(file, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/edm-imagenet-64x64-cond-adm.pkl', 'rb') as f:\n",
    "    ckpt = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.map_layer0.weight \t torch.Size([768, 192])\n",
      "model.map_layer0.bias \t torch.Size([768])\n",
      "model.map_layer1.weight \t torch.Size([768, 768])\n",
      "model.map_layer1.bias \t torch.Size([768])\n",
      "model.map_label.weight \t torch.Size([768, 1000])\n",
      "model.enc.64x64_conv.weight \t torch.Size([192, 3, 3, 3])\n",
      "model.enc.64x64_conv.bias \t torch.Size([192])\n",
      "model.enc.64x64_block0.norm0.weight \t torch.Size([192])\n",
      "model.enc.64x64_block0.norm0.bias \t torch.Size([192])\n",
      "model.enc.64x64_block0.conv0.weight \t torch.Size([192, 192, 3, 3])\n",
      "model.enc.64x64_block0.conv0.bias \t torch.Size([192])\n",
      "model.enc.64x64_block0.affine.weight \t torch.Size([384, 768])\n",
      "model.enc.64x64_block0.affine.bias \t torch.Size([384])\n",
      "model.enc.64x64_block0.norm1.weight \t torch.Size([192])\n",
      "model.enc.64x64_block0.norm1.bias \t torch.Size([192])\n",
      "model.enc.64x64_block0.conv1.weight \t torch.Size([192, 192, 3, 3])\n",
      "model.enc.64x64_block0.conv1.bias \t torch.Size([192])\n",
      "model.enc.64x64_block1.norm0.weight \t torch.Size([192])\n",
      "model.enc.64x64_block1.norm0.bias \t torch.Size([192])\n",
      "model.enc.64x64_block1.conv0.weight \t torch.Size([192, 192, 3, 3])\n",
      "model.enc.64x64_block1.conv0.bias \t torch.Size([192])\n",
      "model.enc.64x64_block1.affine.weight \t torch.Size([384, 768])\n",
      "model.enc.64x64_block1.affine.bias \t torch.Size([384])\n",
      "model.enc.64x64_block1.norm1.weight \t torch.Size([192])\n",
      "model.enc.64x64_block1.norm1.bias \t torch.Size([192])\n",
      "model.enc.64x64_block1.conv1.weight \t torch.Size([192, 192, 3, 3])\n",
      "model.enc.64x64_block1.conv1.bias \t torch.Size([192])\n",
      "model.enc.64x64_block2.norm0.weight \t torch.Size([192])\n",
      "model.enc.64x64_block2.norm0.bias \t torch.Size([192])\n",
      "model.enc.64x64_block2.conv0.weight \t torch.Size([192, 192, 3, 3])\n",
      "model.enc.64x64_block2.conv0.bias \t torch.Size([192])\n",
      "model.enc.64x64_block2.affine.weight \t torch.Size([384, 768])\n",
      "model.enc.64x64_block2.affine.bias \t torch.Size([384])\n",
      "model.enc.64x64_block2.norm1.weight \t torch.Size([192])\n",
      "model.enc.64x64_block2.norm1.bias \t torch.Size([192])\n",
      "model.enc.64x64_block2.conv1.weight \t torch.Size([192, 192, 3, 3])\n",
      "model.enc.64x64_block2.conv1.bias \t torch.Size([192])\n",
      "model.enc.32x32_down.norm0.weight \t torch.Size([192])\n",
      "model.enc.32x32_down.norm0.bias \t torch.Size([192])\n",
      "model.enc.32x32_down.conv0.weight \t torch.Size([192, 192, 3, 3])\n",
      "model.enc.32x32_down.conv0.bias \t torch.Size([192])\n",
      "model.enc.32x32_down.conv0.resample_filter \t torch.Size([1, 1, 2, 2])\n",
      "model.enc.32x32_down.affine.weight \t torch.Size([384, 768])\n",
      "model.enc.32x32_down.affine.bias \t torch.Size([384])\n",
      "model.enc.32x32_down.norm1.weight \t torch.Size([192])\n",
      "model.enc.32x32_down.norm1.bias \t torch.Size([192])\n",
      "model.enc.32x32_down.conv1.weight \t torch.Size([192, 192, 3, 3])\n",
      "model.enc.32x32_down.conv1.bias \t torch.Size([192])\n",
      "model.enc.32x32_down.skip.resample_filter \t torch.Size([1, 1, 2, 2])\n",
      "model.enc.32x32_block0.norm0.weight \t torch.Size([192])\n",
      "model.enc.32x32_block0.norm0.bias \t torch.Size([192])\n",
      "model.enc.32x32_block0.conv0.weight \t torch.Size([384, 192, 3, 3])\n",
      "model.enc.32x32_block0.conv0.bias \t torch.Size([384])\n",
      "model.enc.32x32_block0.affine.weight \t torch.Size([768, 768])\n",
      "model.enc.32x32_block0.affine.bias \t torch.Size([768])\n",
      "model.enc.32x32_block0.norm1.weight \t torch.Size([384])\n",
      "model.enc.32x32_block0.norm1.bias \t torch.Size([384])\n",
      "model.enc.32x32_block0.conv1.weight \t torch.Size([384, 384, 3, 3])\n",
      "model.enc.32x32_block0.conv1.bias \t torch.Size([384])\n",
      "model.enc.32x32_block0.skip.weight \t torch.Size([384, 192, 1, 1])\n",
      "model.enc.32x32_block0.skip.bias \t torch.Size([384])\n",
      "model.enc.32x32_block0.norm2.weight \t torch.Size([384])\n",
      "model.enc.32x32_block0.norm2.bias \t torch.Size([384])\n",
      "model.enc.32x32_block0.qkv.weight \t torch.Size([1152, 384, 1, 1])\n",
      "model.enc.32x32_block0.qkv.bias \t torch.Size([1152])\n",
      "model.enc.32x32_block0.proj.weight \t torch.Size([384, 384, 1, 1])\n",
      "model.enc.32x32_block0.proj.bias \t torch.Size([384])\n",
      "model.enc.32x32_block1.norm0.weight \t torch.Size([384])\n",
      "model.enc.32x32_block1.norm0.bias \t torch.Size([384])\n",
      "model.enc.32x32_block1.conv0.weight \t torch.Size([384, 384, 3, 3])\n",
      "model.enc.32x32_block1.conv0.bias \t torch.Size([384])\n",
      "model.enc.32x32_block1.affine.weight \t torch.Size([768, 768])\n",
      "model.enc.32x32_block1.affine.bias \t torch.Size([768])\n",
      "model.enc.32x32_block1.norm1.weight \t torch.Size([384])\n",
      "model.enc.32x32_block1.norm1.bias \t torch.Size([384])\n",
      "model.enc.32x32_block1.conv1.weight \t torch.Size([384, 384, 3, 3])\n",
      "model.enc.32x32_block1.conv1.bias \t torch.Size([384])\n",
      "model.enc.32x32_block1.norm2.weight \t torch.Size([384])\n",
      "model.enc.32x32_block1.norm2.bias \t torch.Size([384])\n",
      "model.enc.32x32_block1.qkv.weight \t torch.Size([1152, 384, 1, 1])\n",
      "model.enc.32x32_block1.qkv.bias \t torch.Size([1152])\n",
      "model.enc.32x32_block1.proj.weight \t torch.Size([384, 384, 1, 1])\n",
      "model.enc.32x32_block1.proj.bias \t torch.Size([384])\n",
      "model.enc.32x32_block2.norm0.weight \t torch.Size([384])\n",
      "model.enc.32x32_block2.norm0.bias \t torch.Size([384])\n",
      "model.enc.32x32_block2.conv0.weight \t torch.Size([384, 384, 3, 3])\n",
      "model.enc.32x32_block2.conv0.bias \t torch.Size([384])\n",
      "model.enc.32x32_block2.affine.weight \t torch.Size([768, 768])\n",
      "model.enc.32x32_block2.affine.bias \t torch.Size([768])\n",
      "model.enc.32x32_block2.norm1.weight \t torch.Size([384])\n",
      "model.enc.32x32_block2.norm1.bias \t torch.Size([384])\n",
      "model.enc.32x32_block2.conv1.weight \t torch.Size([384, 384, 3, 3])\n",
      "model.enc.32x32_block2.conv1.bias \t torch.Size([384])\n",
      "model.enc.32x32_block2.norm2.weight \t torch.Size([384])\n",
      "model.enc.32x32_block2.norm2.bias \t torch.Size([384])\n",
      "model.enc.32x32_block2.qkv.weight \t torch.Size([1152, 384, 1, 1])\n",
      "model.enc.32x32_block2.qkv.bias \t torch.Size([1152])\n",
      "model.enc.32x32_block2.proj.weight \t torch.Size([384, 384, 1, 1])\n",
      "model.enc.32x32_block2.proj.bias \t torch.Size([384])\n",
      "model.enc.16x16_down.norm0.weight \t torch.Size([384])\n",
      "model.enc.16x16_down.norm0.bias \t torch.Size([384])\n",
      "model.enc.16x16_down.conv0.weight \t torch.Size([384, 384, 3, 3])\n",
      "model.enc.16x16_down.conv0.bias \t torch.Size([384])\n",
      "model.enc.16x16_down.conv0.resample_filter \t torch.Size([1, 1, 2, 2])\n",
      "model.enc.16x16_down.affine.weight \t torch.Size([768, 768])\n",
      "model.enc.16x16_down.affine.bias \t torch.Size([768])\n",
      "model.enc.16x16_down.norm1.weight \t torch.Size([384])\n",
      "model.enc.16x16_down.norm1.bias \t torch.Size([384])\n",
      "model.enc.16x16_down.conv1.weight \t torch.Size([384, 384, 3, 3])\n",
      "model.enc.16x16_down.conv1.bias \t torch.Size([384])\n",
      "model.enc.16x16_down.skip.resample_filter \t torch.Size([1, 1, 2, 2])\n",
      "model.enc.16x16_block0.norm0.weight \t torch.Size([384])\n",
      "model.enc.16x16_block0.norm0.bias \t torch.Size([384])\n",
      "model.enc.16x16_block0.conv0.weight \t torch.Size([576, 384, 3, 3])\n",
      "model.enc.16x16_block0.conv0.bias \t torch.Size([576])\n",
      "model.enc.16x16_block0.affine.weight \t torch.Size([1152, 768])\n",
      "model.enc.16x16_block0.affine.bias \t torch.Size([1152])\n",
      "model.enc.16x16_block0.norm1.weight \t torch.Size([576])\n",
      "model.enc.16x16_block0.norm1.bias \t torch.Size([576])\n",
      "model.enc.16x16_block0.conv1.weight \t torch.Size([576, 576, 3, 3])\n",
      "model.enc.16x16_block0.conv1.bias \t torch.Size([576])\n",
      "model.enc.16x16_block0.skip.weight \t torch.Size([576, 384, 1, 1])\n",
      "model.enc.16x16_block0.skip.bias \t torch.Size([576])\n",
      "model.enc.16x16_block0.norm2.weight \t torch.Size([576])\n",
      "model.enc.16x16_block0.norm2.bias \t torch.Size([576])\n",
      "model.enc.16x16_block0.qkv.weight \t torch.Size([1728, 576, 1, 1])\n",
      "model.enc.16x16_block0.qkv.bias \t torch.Size([1728])\n",
      "model.enc.16x16_block0.proj.weight \t torch.Size([576, 576, 1, 1])\n",
      "model.enc.16x16_block0.proj.bias \t torch.Size([576])\n",
      "model.enc.16x16_block1.norm0.weight \t torch.Size([576])\n",
      "model.enc.16x16_block1.norm0.bias \t torch.Size([576])\n",
      "model.enc.16x16_block1.conv0.weight \t torch.Size([576, 576, 3, 3])\n",
      "model.enc.16x16_block1.conv0.bias \t torch.Size([576])\n",
      "model.enc.16x16_block1.affine.weight \t torch.Size([1152, 768])\n",
      "model.enc.16x16_block1.affine.bias \t torch.Size([1152])\n",
      "model.enc.16x16_block1.norm1.weight \t torch.Size([576])\n",
      "model.enc.16x16_block1.norm1.bias \t torch.Size([576])\n",
      "model.enc.16x16_block1.conv1.weight \t torch.Size([576, 576, 3, 3])\n",
      "model.enc.16x16_block1.conv1.bias \t torch.Size([576])\n",
      "model.enc.16x16_block1.norm2.weight \t torch.Size([576])\n",
      "model.enc.16x16_block1.norm2.bias \t torch.Size([576])\n",
      "model.enc.16x16_block1.qkv.weight \t torch.Size([1728, 576, 1, 1])\n",
      "model.enc.16x16_block1.qkv.bias \t torch.Size([1728])\n",
      "model.enc.16x16_block1.proj.weight \t torch.Size([576, 576, 1, 1])\n",
      "model.enc.16x16_block1.proj.bias \t torch.Size([576])\n",
      "model.enc.16x16_block2.norm0.weight \t torch.Size([576])\n",
      "model.enc.16x16_block2.norm0.bias \t torch.Size([576])\n",
      "model.enc.16x16_block2.conv0.weight \t torch.Size([576, 576, 3, 3])\n",
      "model.enc.16x16_block2.conv0.bias \t torch.Size([576])\n",
      "model.enc.16x16_block2.affine.weight \t torch.Size([1152, 768])\n",
      "model.enc.16x16_block2.affine.bias \t torch.Size([1152])\n",
      "model.enc.16x16_block2.norm1.weight \t torch.Size([576])\n",
      "model.enc.16x16_block2.norm1.bias \t torch.Size([576])\n",
      "model.enc.16x16_block2.conv1.weight \t torch.Size([576, 576, 3, 3])\n",
      "model.enc.16x16_block2.conv1.bias \t torch.Size([576])\n",
      "model.enc.16x16_block2.norm2.weight \t torch.Size([576])\n",
      "model.enc.16x16_block2.norm2.bias \t torch.Size([576])\n",
      "model.enc.16x16_block2.qkv.weight \t torch.Size([1728, 576, 1, 1])\n",
      "model.enc.16x16_block2.qkv.bias \t torch.Size([1728])\n",
      "model.enc.16x16_block2.proj.weight \t torch.Size([576, 576, 1, 1])\n",
      "model.enc.16x16_block2.proj.bias \t torch.Size([576])\n",
      "model.enc.8x8_down.norm0.weight \t torch.Size([576])\n",
      "model.enc.8x8_down.norm0.bias \t torch.Size([576])\n",
      "model.enc.8x8_down.conv0.weight \t torch.Size([576, 576, 3, 3])\n",
      "model.enc.8x8_down.conv0.bias \t torch.Size([576])\n",
      "model.enc.8x8_down.conv0.resample_filter \t torch.Size([1, 1, 2, 2])\n",
      "model.enc.8x8_down.affine.weight \t torch.Size([1152, 768])\n",
      "model.enc.8x8_down.affine.bias \t torch.Size([1152])\n",
      "model.enc.8x8_down.norm1.weight \t torch.Size([576])\n",
      "model.enc.8x8_down.norm1.bias \t torch.Size([576])\n",
      "model.enc.8x8_down.conv1.weight \t torch.Size([576, 576, 3, 3])\n",
      "model.enc.8x8_down.conv1.bias \t torch.Size([576])\n",
      "model.enc.8x8_down.skip.resample_filter \t torch.Size([1, 1, 2, 2])\n",
      "model.enc.8x8_block0.norm0.weight \t torch.Size([576])\n",
      "model.enc.8x8_block0.norm0.bias \t torch.Size([576])\n",
      "model.enc.8x8_block0.conv0.weight \t torch.Size([768, 576, 3, 3])\n",
      "model.enc.8x8_block0.conv0.bias \t torch.Size([768])\n",
      "model.enc.8x8_block0.affine.weight \t torch.Size([1536, 768])\n",
      "model.enc.8x8_block0.affine.bias \t torch.Size([1536])\n",
      "model.enc.8x8_block0.norm1.weight \t torch.Size([768])\n",
      "model.enc.8x8_block0.norm1.bias \t torch.Size([768])\n",
      "model.enc.8x8_block0.conv1.weight \t torch.Size([768, 768, 3, 3])\n",
      "model.enc.8x8_block0.conv1.bias \t torch.Size([768])\n",
      "model.enc.8x8_block0.skip.weight \t torch.Size([768, 576, 1, 1])\n",
      "model.enc.8x8_block0.skip.bias \t torch.Size([768])\n",
      "model.enc.8x8_block0.norm2.weight \t torch.Size([768])\n",
      "model.enc.8x8_block0.norm2.bias \t torch.Size([768])\n",
      "model.enc.8x8_block0.qkv.weight \t torch.Size([2304, 768, 1, 1])\n",
      "model.enc.8x8_block0.qkv.bias \t torch.Size([2304])\n",
      "model.enc.8x8_block0.proj.weight \t torch.Size([768, 768, 1, 1])\n",
      "model.enc.8x8_block0.proj.bias \t torch.Size([768])\n",
      "model.enc.8x8_block1.norm0.weight \t torch.Size([768])\n",
      "model.enc.8x8_block1.norm0.bias \t torch.Size([768])\n",
      "model.enc.8x8_block1.conv0.weight \t torch.Size([768, 768, 3, 3])\n",
      "model.enc.8x8_block1.conv0.bias \t torch.Size([768])\n",
      "model.enc.8x8_block1.affine.weight \t torch.Size([1536, 768])\n",
      "model.enc.8x8_block1.affine.bias \t torch.Size([1536])\n",
      "model.enc.8x8_block1.norm1.weight \t torch.Size([768])\n",
      "model.enc.8x8_block1.norm1.bias \t torch.Size([768])\n",
      "model.enc.8x8_block1.conv1.weight \t torch.Size([768, 768, 3, 3])\n",
      "model.enc.8x8_block1.conv1.bias \t torch.Size([768])\n",
      "model.enc.8x8_block1.norm2.weight \t torch.Size([768])\n",
      "model.enc.8x8_block1.norm2.bias \t torch.Size([768])\n",
      "model.enc.8x8_block1.qkv.weight \t torch.Size([2304, 768, 1, 1])\n",
      "model.enc.8x8_block1.qkv.bias \t torch.Size([2304])\n",
      "model.enc.8x8_block1.proj.weight \t torch.Size([768, 768, 1, 1])\n",
      "model.enc.8x8_block1.proj.bias \t torch.Size([768])\n",
      "model.enc.8x8_block2.norm0.weight \t torch.Size([768])\n",
      "model.enc.8x8_block2.norm0.bias \t torch.Size([768])\n",
      "model.enc.8x8_block2.conv0.weight \t torch.Size([768, 768, 3, 3])\n",
      "model.enc.8x8_block2.conv0.bias \t torch.Size([768])\n",
      "model.enc.8x8_block2.affine.weight \t torch.Size([1536, 768])\n",
      "model.enc.8x8_block2.affine.bias \t torch.Size([1536])\n",
      "model.enc.8x8_block2.norm1.weight \t torch.Size([768])\n",
      "model.enc.8x8_block2.norm1.bias \t torch.Size([768])\n",
      "model.enc.8x8_block2.conv1.weight \t torch.Size([768, 768, 3, 3])\n",
      "model.enc.8x8_block2.conv1.bias \t torch.Size([768])\n",
      "model.enc.8x8_block2.norm2.weight \t torch.Size([768])\n",
      "model.enc.8x8_block2.norm2.bias \t torch.Size([768])\n",
      "model.enc.8x8_block2.qkv.weight \t torch.Size([2304, 768, 1, 1])\n",
      "model.enc.8x8_block2.qkv.bias \t torch.Size([2304])\n",
      "model.enc.8x8_block2.proj.weight \t torch.Size([768, 768, 1, 1])\n",
      "model.enc.8x8_block2.proj.bias \t torch.Size([768])\n",
      "model.dec.8x8_in0.norm0.weight \t torch.Size([768])\n",
      "model.dec.8x8_in0.norm0.bias \t torch.Size([768])\n",
      "model.dec.8x8_in0.conv0.weight \t torch.Size([768, 768, 3, 3])\n",
      "model.dec.8x8_in0.conv0.bias \t torch.Size([768])\n",
      "model.dec.8x8_in0.affine.weight \t torch.Size([1536, 768])\n",
      "model.dec.8x8_in0.affine.bias \t torch.Size([1536])\n",
      "model.dec.8x8_in0.norm1.weight \t torch.Size([768])\n",
      "model.dec.8x8_in0.norm1.bias \t torch.Size([768])\n",
      "model.dec.8x8_in0.conv1.weight \t torch.Size([768, 768, 3, 3])\n",
      "model.dec.8x8_in0.conv1.bias \t torch.Size([768])\n",
      "model.dec.8x8_in0.norm2.weight \t torch.Size([768])\n",
      "model.dec.8x8_in0.norm2.bias \t torch.Size([768])\n",
      "model.dec.8x8_in0.qkv.weight \t torch.Size([2304, 768, 1, 1])\n",
      "model.dec.8x8_in0.qkv.bias \t torch.Size([2304])\n",
      "model.dec.8x8_in0.proj.weight \t torch.Size([768, 768, 1, 1])\n",
      "model.dec.8x8_in0.proj.bias \t torch.Size([768])\n",
      "model.dec.8x8_in1.norm0.weight \t torch.Size([768])\n",
      "model.dec.8x8_in1.norm0.bias \t torch.Size([768])\n",
      "model.dec.8x8_in1.conv0.weight \t torch.Size([768, 768, 3, 3])\n",
      "model.dec.8x8_in1.conv0.bias \t torch.Size([768])\n",
      "model.dec.8x8_in1.affine.weight \t torch.Size([1536, 768])\n",
      "model.dec.8x8_in1.affine.bias \t torch.Size([1536])\n",
      "model.dec.8x8_in1.norm1.weight \t torch.Size([768])\n",
      "model.dec.8x8_in1.norm1.bias \t torch.Size([768])\n",
      "model.dec.8x8_in1.conv1.weight \t torch.Size([768, 768, 3, 3])\n",
      "model.dec.8x8_in1.conv1.bias \t torch.Size([768])\n",
      "model.dec.8x8_block0.norm0.weight \t torch.Size([1536])\n",
      "model.dec.8x8_block0.norm0.bias \t torch.Size([1536])\n",
      "model.dec.8x8_block0.conv0.weight \t torch.Size([768, 1536, 3, 3])\n",
      "model.dec.8x8_block0.conv0.bias \t torch.Size([768])\n",
      "model.dec.8x8_block0.affine.weight \t torch.Size([1536, 768])\n",
      "model.dec.8x8_block0.affine.bias \t torch.Size([1536])\n",
      "model.dec.8x8_block0.norm1.weight \t torch.Size([768])\n",
      "model.dec.8x8_block0.norm1.bias \t torch.Size([768])\n",
      "model.dec.8x8_block0.conv1.weight \t torch.Size([768, 768, 3, 3])\n",
      "model.dec.8x8_block0.conv1.bias \t torch.Size([768])\n",
      "model.dec.8x8_block0.skip.weight \t torch.Size([768, 1536, 1, 1])\n",
      "model.dec.8x8_block0.skip.bias \t torch.Size([768])\n",
      "model.dec.8x8_block0.norm2.weight \t torch.Size([768])\n",
      "model.dec.8x8_block0.norm2.bias \t torch.Size([768])\n",
      "model.dec.8x8_block0.qkv.weight \t torch.Size([2304, 768, 1, 1])\n",
      "model.dec.8x8_block0.qkv.bias \t torch.Size([2304])\n",
      "model.dec.8x8_block0.proj.weight \t torch.Size([768, 768, 1, 1])\n",
      "model.dec.8x8_block0.proj.bias \t torch.Size([768])\n",
      "model.dec.8x8_block1.norm0.weight \t torch.Size([1536])\n",
      "model.dec.8x8_block1.norm0.bias \t torch.Size([1536])\n",
      "model.dec.8x8_block1.conv0.weight \t torch.Size([768, 1536, 3, 3])\n",
      "model.dec.8x8_block1.conv0.bias \t torch.Size([768])\n",
      "model.dec.8x8_block1.affine.weight \t torch.Size([1536, 768])\n",
      "model.dec.8x8_block1.affine.bias \t torch.Size([1536])\n",
      "model.dec.8x8_block1.norm1.weight \t torch.Size([768])\n",
      "model.dec.8x8_block1.norm1.bias \t torch.Size([768])\n",
      "model.dec.8x8_block1.conv1.weight \t torch.Size([768, 768, 3, 3])\n",
      "model.dec.8x8_block1.conv1.bias \t torch.Size([768])\n",
      "model.dec.8x8_block1.skip.weight \t torch.Size([768, 1536, 1, 1])\n",
      "model.dec.8x8_block1.skip.bias \t torch.Size([768])\n",
      "model.dec.8x8_block1.norm2.weight \t torch.Size([768])\n",
      "model.dec.8x8_block1.norm2.bias \t torch.Size([768])\n",
      "model.dec.8x8_block1.qkv.weight \t torch.Size([2304, 768, 1, 1])\n",
      "model.dec.8x8_block1.qkv.bias \t torch.Size([2304])\n",
      "model.dec.8x8_block1.proj.weight \t torch.Size([768, 768, 1, 1])\n",
      "model.dec.8x8_block1.proj.bias \t torch.Size([768])\n",
      "model.dec.8x8_block2.norm0.weight \t torch.Size([1536])\n",
      "model.dec.8x8_block2.norm0.bias \t torch.Size([1536])\n",
      "model.dec.8x8_block2.conv0.weight \t torch.Size([768, 1536, 3, 3])\n",
      "model.dec.8x8_block2.conv0.bias \t torch.Size([768])\n",
      "model.dec.8x8_block2.affine.weight \t torch.Size([1536, 768])\n",
      "model.dec.8x8_block2.affine.bias \t torch.Size([1536])\n",
      "model.dec.8x8_block2.norm1.weight \t torch.Size([768])\n",
      "model.dec.8x8_block2.norm1.bias \t torch.Size([768])\n",
      "model.dec.8x8_block2.conv1.weight \t torch.Size([768, 768, 3, 3])\n",
      "model.dec.8x8_block2.conv1.bias \t torch.Size([768])\n",
      "model.dec.8x8_block2.skip.weight \t torch.Size([768, 1536, 1, 1])\n",
      "model.dec.8x8_block2.skip.bias \t torch.Size([768])\n",
      "model.dec.8x8_block2.norm2.weight \t torch.Size([768])\n",
      "model.dec.8x8_block2.norm2.bias \t torch.Size([768])\n",
      "model.dec.8x8_block2.qkv.weight \t torch.Size([2304, 768, 1, 1])\n",
      "model.dec.8x8_block2.qkv.bias \t torch.Size([2304])\n",
      "model.dec.8x8_block2.proj.weight \t torch.Size([768, 768, 1, 1])\n",
      "model.dec.8x8_block2.proj.bias \t torch.Size([768])\n",
      "model.dec.8x8_block3.norm0.weight \t torch.Size([1344])\n",
      "model.dec.8x8_block3.norm0.bias \t torch.Size([1344])\n",
      "model.dec.8x8_block3.conv0.weight \t torch.Size([768, 1344, 3, 3])\n",
      "model.dec.8x8_block3.conv0.bias \t torch.Size([768])\n",
      "model.dec.8x8_block3.affine.weight \t torch.Size([1536, 768])\n",
      "model.dec.8x8_block3.affine.bias \t torch.Size([1536])\n",
      "model.dec.8x8_block3.norm1.weight \t torch.Size([768])\n",
      "model.dec.8x8_block3.norm1.bias \t torch.Size([768])\n",
      "model.dec.8x8_block3.conv1.weight \t torch.Size([768, 768, 3, 3])\n",
      "model.dec.8x8_block3.conv1.bias \t torch.Size([768])\n",
      "model.dec.8x8_block3.skip.weight \t torch.Size([768, 1344, 1, 1])\n",
      "model.dec.8x8_block3.skip.bias \t torch.Size([768])\n",
      "model.dec.8x8_block3.norm2.weight \t torch.Size([768])\n",
      "model.dec.8x8_block3.norm2.bias \t torch.Size([768])\n",
      "model.dec.8x8_block3.qkv.weight \t torch.Size([2304, 768, 1, 1])\n",
      "model.dec.8x8_block3.qkv.bias \t torch.Size([2304])\n",
      "model.dec.8x8_block3.proj.weight \t torch.Size([768, 768, 1, 1])\n",
      "model.dec.8x8_block3.proj.bias \t torch.Size([768])\n",
      "model.dec.16x16_up.norm0.weight \t torch.Size([768])\n",
      "model.dec.16x16_up.norm0.bias \t torch.Size([768])\n",
      "model.dec.16x16_up.conv0.weight \t torch.Size([768, 768, 3, 3])\n",
      "model.dec.16x16_up.conv0.bias \t torch.Size([768])\n",
      "model.dec.16x16_up.conv0.resample_filter \t torch.Size([1, 1, 2, 2])\n",
      "model.dec.16x16_up.affine.weight \t torch.Size([1536, 768])\n",
      "model.dec.16x16_up.affine.bias \t torch.Size([1536])\n",
      "model.dec.16x16_up.norm1.weight \t torch.Size([768])\n",
      "model.dec.16x16_up.norm1.bias \t torch.Size([768])\n",
      "model.dec.16x16_up.conv1.weight \t torch.Size([768, 768, 3, 3])\n",
      "model.dec.16x16_up.conv1.bias \t torch.Size([768])\n",
      "model.dec.16x16_up.skip.resample_filter \t torch.Size([1, 1, 2, 2])\n",
      "model.dec.16x16_block0.norm0.weight \t torch.Size([1344])\n",
      "model.dec.16x16_block0.norm0.bias \t torch.Size([1344])\n",
      "model.dec.16x16_block0.conv0.weight \t torch.Size([576, 1344, 3, 3])\n",
      "model.dec.16x16_block0.conv0.bias \t torch.Size([576])\n",
      "model.dec.16x16_block0.affine.weight \t torch.Size([1152, 768])\n",
      "model.dec.16x16_block0.affine.bias \t torch.Size([1152])\n",
      "model.dec.16x16_block0.norm1.weight \t torch.Size([576])\n",
      "model.dec.16x16_block0.norm1.bias \t torch.Size([576])\n",
      "model.dec.16x16_block0.conv1.weight \t torch.Size([576, 576, 3, 3])\n",
      "model.dec.16x16_block0.conv1.bias \t torch.Size([576])\n",
      "model.dec.16x16_block0.skip.weight \t torch.Size([576, 1344, 1, 1])\n",
      "model.dec.16x16_block0.skip.bias \t torch.Size([576])\n",
      "model.dec.16x16_block0.norm2.weight \t torch.Size([576])\n",
      "model.dec.16x16_block0.norm2.bias \t torch.Size([576])\n",
      "model.dec.16x16_block0.qkv.weight \t torch.Size([1728, 576, 1, 1])\n",
      "model.dec.16x16_block0.qkv.bias \t torch.Size([1728])\n",
      "model.dec.16x16_block0.proj.weight \t torch.Size([576, 576, 1, 1])\n",
      "model.dec.16x16_block0.proj.bias \t torch.Size([576])\n",
      "model.dec.16x16_block1.norm0.weight \t torch.Size([1152])\n",
      "model.dec.16x16_block1.norm0.bias \t torch.Size([1152])\n",
      "model.dec.16x16_block1.conv0.weight \t torch.Size([576, 1152, 3, 3])\n",
      "model.dec.16x16_block1.conv0.bias \t torch.Size([576])\n",
      "model.dec.16x16_block1.affine.weight \t torch.Size([1152, 768])\n",
      "model.dec.16x16_block1.affine.bias \t torch.Size([1152])\n",
      "model.dec.16x16_block1.norm1.weight \t torch.Size([576])\n",
      "model.dec.16x16_block1.norm1.bias \t torch.Size([576])\n",
      "model.dec.16x16_block1.conv1.weight \t torch.Size([576, 576, 3, 3])\n",
      "model.dec.16x16_block1.conv1.bias \t torch.Size([576])\n",
      "model.dec.16x16_block1.skip.weight \t torch.Size([576, 1152, 1, 1])\n",
      "model.dec.16x16_block1.skip.bias \t torch.Size([576])\n",
      "model.dec.16x16_block1.norm2.weight \t torch.Size([576])\n",
      "model.dec.16x16_block1.norm2.bias \t torch.Size([576])\n",
      "model.dec.16x16_block1.qkv.weight \t torch.Size([1728, 576, 1, 1])\n",
      "model.dec.16x16_block1.qkv.bias \t torch.Size([1728])\n",
      "model.dec.16x16_block1.proj.weight \t torch.Size([576, 576, 1, 1])\n",
      "model.dec.16x16_block1.proj.bias \t torch.Size([576])\n",
      "model.dec.16x16_block2.norm0.weight \t torch.Size([1152])\n",
      "model.dec.16x16_block2.norm0.bias \t torch.Size([1152])\n",
      "model.dec.16x16_block2.conv0.weight \t torch.Size([576, 1152, 3, 3])\n",
      "model.dec.16x16_block2.conv0.bias \t torch.Size([576])\n",
      "model.dec.16x16_block2.affine.weight \t torch.Size([1152, 768])\n",
      "model.dec.16x16_block2.affine.bias \t torch.Size([1152])\n",
      "model.dec.16x16_block2.norm1.weight \t torch.Size([576])\n",
      "model.dec.16x16_block2.norm1.bias \t torch.Size([576])\n",
      "model.dec.16x16_block2.conv1.weight \t torch.Size([576, 576, 3, 3])\n",
      "model.dec.16x16_block2.conv1.bias \t torch.Size([576])\n",
      "model.dec.16x16_block2.skip.weight \t torch.Size([576, 1152, 1, 1])\n",
      "model.dec.16x16_block2.skip.bias \t torch.Size([576])\n",
      "model.dec.16x16_block2.norm2.weight \t torch.Size([576])\n",
      "model.dec.16x16_block2.norm2.bias \t torch.Size([576])\n",
      "model.dec.16x16_block2.qkv.weight \t torch.Size([1728, 576, 1, 1])\n",
      "model.dec.16x16_block2.qkv.bias \t torch.Size([1728])\n",
      "model.dec.16x16_block2.proj.weight \t torch.Size([576, 576, 1, 1])\n",
      "model.dec.16x16_block2.proj.bias \t torch.Size([576])\n",
      "model.dec.16x16_block3.norm0.weight \t torch.Size([960])\n",
      "model.dec.16x16_block3.norm0.bias \t torch.Size([960])\n",
      "model.dec.16x16_block3.conv0.weight \t torch.Size([576, 960, 3, 3])\n",
      "model.dec.16x16_block3.conv0.bias \t torch.Size([576])\n",
      "model.dec.16x16_block3.affine.weight \t torch.Size([1152, 768])\n",
      "model.dec.16x16_block3.affine.bias \t torch.Size([1152])\n",
      "model.dec.16x16_block3.norm1.weight \t torch.Size([576])\n",
      "model.dec.16x16_block3.norm1.bias \t torch.Size([576])\n",
      "model.dec.16x16_block3.conv1.weight \t torch.Size([576, 576, 3, 3])\n",
      "model.dec.16x16_block3.conv1.bias \t torch.Size([576])\n",
      "model.dec.16x16_block3.skip.weight \t torch.Size([576, 960, 1, 1])\n",
      "model.dec.16x16_block3.skip.bias \t torch.Size([576])\n",
      "model.dec.16x16_block3.norm2.weight \t torch.Size([576])\n",
      "model.dec.16x16_block3.norm2.bias \t torch.Size([576])\n",
      "model.dec.16x16_block3.qkv.weight \t torch.Size([1728, 576, 1, 1])\n",
      "model.dec.16x16_block3.qkv.bias \t torch.Size([1728])\n",
      "model.dec.16x16_block3.proj.weight \t torch.Size([576, 576, 1, 1])\n",
      "model.dec.16x16_block3.proj.bias \t torch.Size([576])\n",
      "model.dec.32x32_up.norm0.weight \t torch.Size([576])\n",
      "model.dec.32x32_up.norm0.bias \t torch.Size([576])\n",
      "model.dec.32x32_up.conv0.weight \t torch.Size([576, 576, 3, 3])\n",
      "model.dec.32x32_up.conv0.bias \t torch.Size([576])\n",
      "model.dec.32x32_up.conv0.resample_filter \t torch.Size([1, 1, 2, 2])\n",
      "model.dec.32x32_up.affine.weight \t torch.Size([1152, 768])\n",
      "model.dec.32x32_up.affine.bias \t torch.Size([1152])\n",
      "model.dec.32x32_up.norm1.weight \t torch.Size([576])\n",
      "model.dec.32x32_up.norm1.bias \t torch.Size([576])\n",
      "model.dec.32x32_up.conv1.weight \t torch.Size([576, 576, 3, 3])\n",
      "model.dec.32x32_up.conv1.bias \t torch.Size([576])\n",
      "model.dec.32x32_up.skip.resample_filter \t torch.Size([1, 1, 2, 2])\n",
      "model.dec.32x32_block0.norm0.weight \t torch.Size([960])\n",
      "model.dec.32x32_block0.norm0.bias \t torch.Size([960])\n",
      "model.dec.32x32_block0.conv0.weight \t torch.Size([384, 960, 3, 3])\n",
      "model.dec.32x32_block0.conv0.bias \t torch.Size([384])\n",
      "model.dec.32x32_block0.affine.weight \t torch.Size([768, 768])\n",
      "model.dec.32x32_block0.affine.bias \t torch.Size([768])\n",
      "model.dec.32x32_block0.norm1.weight \t torch.Size([384])\n",
      "model.dec.32x32_block0.norm1.bias \t torch.Size([384])\n",
      "model.dec.32x32_block0.conv1.weight \t torch.Size([384, 384, 3, 3])\n",
      "model.dec.32x32_block0.conv1.bias \t torch.Size([384])\n",
      "model.dec.32x32_block0.skip.weight \t torch.Size([384, 960, 1, 1])\n",
      "model.dec.32x32_block0.skip.bias \t torch.Size([384])\n",
      "model.dec.32x32_block0.norm2.weight \t torch.Size([384])\n",
      "model.dec.32x32_block0.norm2.bias \t torch.Size([384])\n",
      "model.dec.32x32_block0.qkv.weight \t torch.Size([1152, 384, 1, 1])\n",
      "model.dec.32x32_block0.qkv.bias \t torch.Size([1152])\n",
      "model.dec.32x32_block0.proj.weight \t torch.Size([384, 384, 1, 1])\n",
      "model.dec.32x32_block0.proj.bias \t torch.Size([384])\n",
      "model.dec.32x32_block1.norm0.weight \t torch.Size([768])\n",
      "model.dec.32x32_block1.norm0.bias \t torch.Size([768])\n",
      "model.dec.32x32_block1.conv0.weight \t torch.Size([384, 768, 3, 3])\n",
      "model.dec.32x32_block1.conv0.bias \t torch.Size([384])\n",
      "model.dec.32x32_block1.affine.weight \t torch.Size([768, 768])\n",
      "model.dec.32x32_block1.affine.bias \t torch.Size([768])\n",
      "model.dec.32x32_block1.norm1.weight \t torch.Size([384])\n",
      "model.dec.32x32_block1.norm1.bias \t torch.Size([384])\n",
      "model.dec.32x32_block1.conv1.weight \t torch.Size([384, 384, 3, 3])\n",
      "model.dec.32x32_block1.conv1.bias \t torch.Size([384])\n",
      "model.dec.32x32_block1.skip.weight \t torch.Size([384, 768, 1, 1])\n",
      "model.dec.32x32_block1.skip.bias \t torch.Size([384])\n",
      "model.dec.32x32_block1.norm2.weight \t torch.Size([384])\n",
      "model.dec.32x32_block1.norm2.bias \t torch.Size([384])\n",
      "model.dec.32x32_block1.qkv.weight \t torch.Size([1152, 384, 1, 1])\n",
      "model.dec.32x32_block1.qkv.bias \t torch.Size([1152])\n",
      "model.dec.32x32_block1.proj.weight \t torch.Size([384, 384, 1, 1])\n",
      "model.dec.32x32_block1.proj.bias \t torch.Size([384])\n",
      "model.dec.32x32_block2.norm0.weight \t torch.Size([768])\n",
      "model.dec.32x32_block2.norm0.bias \t torch.Size([768])\n",
      "model.dec.32x32_block2.conv0.weight \t torch.Size([384, 768, 3, 3])\n",
      "model.dec.32x32_block2.conv0.bias \t torch.Size([384])\n",
      "model.dec.32x32_block2.affine.weight \t torch.Size([768, 768])\n",
      "model.dec.32x32_block2.affine.bias \t torch.Size([768])\n",
      "model.dec.32x32_block2.norm1.weight \t torch.Size([384])\n",
      "model.dec.32x32_block2.norm1.bias \t torch.Size([384])\n",
      "model.dec.32x32_block2.conv1.weight \t torch.Size([384, 384, 3, 3])\n",
      "model.dec.32x32_block2.conv1.bias \t torch.Size([384])\n",
      "model.dec.32x32_block2.skip.weight \t torch.Size([384, 768, 1, 1])\n",
      "model.dec.32x32_block2.skip.bias \t torch.Size([384])\n",
      "model.dec.32x32_block2.norm2.weight \t torch.Size([384])\n",
      "model.dec.32x32_block2.norm2.bias \t torch.Size([384])\n",
      "model.dec.32x32_block2.qkv.weight \t torch.Size([1152, 384, 1, 1])\n",
      "model.dec.32x32_block2.qkv.bias \t torch.Size([1152])\n",
      "model.dec.32x32_block2.proj.weight \t torch.Size([384, 384, 1, 1])\n",
      "model.dec.32x32_block2.proj.bias \t torch.Size([384])\n",
      "model.dec.32x32_block3.norm0.weight \t torch.Size([576])\n",
      "model.dec.32x32_block3.norm0.bias \t torch.Size([576])\n",
      "model.dec.32x32_block3.conv0.weight \t torch.Size([384, 576, 3, 3])\n",
      "model.dec.32x32_block3.conv0.bias \t torch.Size([384])\n",
      "model.dec.32x32_block3.affine.weight \t torch.Size([768, 768])\n",
      "model.dec.32x32_block3.affine.bias \t torch.Size([768])\n",
      "model.dec.32x32_block3.norm1.weight \t torch.Size([384])\n",
      "model.dec.32x32_block3.norm1.bias \t torch.Size([384])\n",
      "model.dec.32x32_block3.conv1.weight \t torch.Size([384, 384, 3, 3])\n",
      "model.dec.32x32_block3.conv1.bias \t torch.Size([384])\n",
      "model.dec.32x32_block3.skip.weight \t torch.Size([384, 576, 1, 1])\n",
      "model.dec.32x32_block3.skip.bias \t torch.Size([384])\n",
      "model.dec.32x32_block3.norm2.weight \t torch.Size([384])\n",
      "model.dec.32x32_block3.norm2.bias \t torch.Size([384])\n",
      "model.dec.32x32_block3.qkv.weight \t torch.Size([1152, 384, 1, 1])\n",
      "model.dec.32x32_block3.qkv.bias \t torch.Size([1152])\n",
      "model.dec.32x32_block3.proj.weight \t torch.Size([384, 384, 1, 1])\n",
      "model.dec.32x32_block3.proj.bias \t torch.Size([384])\n",
      "model.dec.64x64_up.norm0.weight \t torch.Size([384])\n",
      "model.dec.64x64_up.norm0.bias \t torch.Size([384])\n",
      "model.dec.64x64_up.conv0.weight \t torch.Size([384, 384, 3, 3])\n",
      "model.dec.64x64_up.conv0.bias \t torch.Size([384])\n",
      "model.dec.64x64_up.conv0.resample_filter \t torch.Size([1, 1, 2, 2])\n",
      "model.dec.64x64_up.affine.weight \t torch.Size([768, 768])\n",
      "model.dec.64x64_up.affine.bias \t torch.Size([768])\n",
      "model.dec.64x64_up.norm1.weight \t torch.Size([384])\n",
      "model.dec.64x64_up.norm1.bias \t torch.Size([384])\n",
      "model.dec.64x64_up.conv1.weight \t torch.Size([384, 384, 3, 3])\n",
      "model.dec.64x64_up.conv1.bias \t torch.Size([384])\n",
      "model.dec.64x64_up.skip.resample_filter \t torch.Size([1, 1, 2, 2])\n",
      "model.dec.64x64_block0.norm0.weight \t torch.Size([576])\n",
      "model.dec.64x64_block0.norm0.bias \t torch.Size([576])\n",
      "model.dec.64x64_block0.conv0.weight \t torch.Size([192, 576, 3, 3])\n",
      "model.dec.64x64_block0.conv0.bias \t torch.Size([192])\n",
      "model.dec.64x64_block0.affine.weight \t torch.Size([384, 768])\n",
      "model.dec.64x64_block0.affine.bias \t torch.Size([384])\n",
      "model.dec.64x64_block0.norm1.weight \t torch.Size([192])\n",
      "model.dec.64x64_block0.norm1.bias \t torch.Size([192])\n",
      "model.dec.64x64_block0.conv1.weight \t torch.Size([192, 192, 3, 3])\n",
      "model.dec.64x64_block0.conv1.bias \t torch.Size([192])\n",
      "model.dec.64x64_block0.skip.weight \t torch.Size([192, 576, 1, 1])\n",
      "model.dec.64x64_block0.skip.bias \t torch.Size([192])\n",
      "model.dec.64x64_block1.norm0.weight \t torch.Size([384])\n",
      "model.dec.64x64_block1.norm0.bias \t torch.Size([384])\n",
      "model.dec.64x64_block1.conv0.weight \t torch.Size([192, 384, 3, 3])\n",
      "model.dec.64x64_block1.conv0.bias \t torch.Size([192])\n",
      "model.dec.64x64_block1.affine.weight \t torch.Size([384, 768])\n",
      "model.dec.64x64_block1.affine.bias \t torch.Size([384])\n",
      "model.dec.64x64_block1.norm1.weight \t torch.Size([192])\n",
      "model.dec.64x64_block1.norm1.bias \t torch.Size([192])\n",
      "model.dec.64x64_block1.conv1.weight \t torch.Size([192, 192, 3, 3])\n",
      "model.dec.64x64_block1.conv1.bias \t torch.Size([192])\n",
      "model.dec.64x64_block1.skip.weight \t torch.Size([192, 384, 1, 1])\n",
      "model.dec.64x64_block1.skip.bias \t torch.Size([192])\n",
      "model.dec.64x64_block2.norm0.weight \t torch.Size([384])\n",
      "model.dec.64x64_block2.norm0.bias \t torch.Size([384])\n",
      "model.dec.64x64_block2.conv0.weight \t torch.Size([192, 384, 3, 3])\n",
      "model.dec.64x64_block2.conv0.bias \t torch.Size([192])\n",
      "model.dec.64x64_block2.affine.weight \t torch.Size([384, 768])\n",
      "model.dec.64x64_block2.affine.bias \t torch.Size([384])\n",
      "model.dec.64x64_block2.norm1.weight \t torch.Size([192])\n",
      "model.dec.64x64_block2.norm1.bias \t torch.Size([192])\n",
      "model.dec.64x64_block2.conv1.weight \t torch.Size([192, 192, 3, 3])\n",
      "model.dec.64x64_block2.conv1.bias \t torch.Size([192])\n",
      "model.dec.64x64_block2.skip.weight \t torch.Size([192, 384, 1, 1])\n",
      "model.dec.64x64_block2.skip.bias \t torch.Size([192])\n",
      "model.dec.64x64_block3.norm0.weight \t torch.Size([384])\n",
      "model.dec.64x64_block3.norm0.bias \t torch.Size([384])\n",
      "model.dec.64x64_block3.conv0.weight \t torch.Size([192, 384, 3, 3])\n",
      "model.dec.64x64_block3.conv0.bias \t torch.Size([192])\n",
      "model.dec.64x64_block3.affine.weight \t torch.Size([384, 768])\n",
      "model.dec.64x64_block3.affine.bias \t torch.Size([384])\n",
      "model.dec.64x64_block3.norm1.weight \t torch.Size([192])\n",
      "model.dec.64x64_block3.norm1.bias \t torch.Size([192])\n",
      "model.dec.64x64_block3.conv1.weight \t torch.Size([192, 192, 3, 3])\n",
      "model.dec.64x64_block3.conv1.bias \t torch.Size([192])\n",
      "model.dec.64x64_block3.skip.weight \t torch.Size([192, 384, 1, 1])\n",
      "model.dec.64x64_block3.skip.bias \t torch.Size([192])\n",
      "model.out_norm.weight \t torch.Size([192])\n",
      "model.out_norm.bias \t torch.Size([192])\n",
      "model.out_conv.weight \t torch.Size([3, 192, 3, 3])\n",
      "model.out_conv.bias \t torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the extracted weights into the corresponding layers of model2\n",
    "# model2.load_state_dict(weights, strict=False)\n",
    "for param_tensor in ckpt['ema'].state_dict():\n",
    "    print(param_tensor, \"\\t\", ckpt['ema'].state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x7f99b0770f90>\n"
     ]
    }
   ],
   "source": [
    "print(ckpt['ema'].model.enc.parameters())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eli",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
